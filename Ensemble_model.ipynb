{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YvgAvzZJ8biMf_rGB7v2OFJOmyMK4_oO",
      "authorship_tag": "ABX9TyP+ZRLytZ3wiuj5fYt0APE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sisn749/Landslide_Susceptibility_GEOG761/blob/main/Ensemble_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract patches\n",
        "\n",
        "NO NEED TO RUN THIS IF YOU ALREADY HAVE THE DATASET"
      ],
      "metadata": {
        "id": "uhQn06w-xGEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------\n",
        "\n",
        "\n",
        "How it works:\n",
        "\n",
        "- Sentinel-2 SR provides L2A reflectance at 10 m.\n",
        "\n",
        "- The .median() composite merges cloud-free pixels from 2019–2022.\n",
        "\n",
        "- Each point.buffer(464 m) yields a ~928 m window around the coordinate.\n",
        "\n",
        "- Patches are exported to Google Drive → “GEE_Landslide_Patches” folder."
      ],
      "metadata": {
        "id": "t-dLRZ83DV9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up GEE API\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='clara-geog761-tryout-1')"
      ],
      "metadata": {
        "id": "ZpGem5uixJNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will transform the numerical long-lat  into GEE points that are georeferenced. The cell after this visualizes these points."
      ],
      "metadata": {
        "id": "36revHaS9-l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/GEOG761 Machine Learning for Remote Sensing/Group project landslide susceptibility/landslides_with_variables_fixed1.csv\")"
      ],
      "metadata": {
        "id": "OppF2g-BxgQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to ee.FeatureCollection\n",
        "def row_to_feature(row):\n",
        "    geom = ee.Geometry.Point(float(row['Longitude']), float(row['Latitude']))\n",
        "    # Make sure 'Valid Landslide' is integer and has no nulls for filtering\n",
        "    label = row['Valid Landslide']\n",
        "    if pd.notna(label):\n",
        "        return ee.Feature(geom, {'id': int(row.name), 'label': int(label)})\n",
        "    else:\n",
        "      print(\"AAAAAAAAAAAAAA\")\n",
        "    return None\n",
        "\n",
        "features = [row_to_feature(r) for _, r in df.iterrows()]\n",
        "features = [f for f in features if f is not None] # Remove null features\n",
        "fc = ee.FeatureCollection(features)\n",
        "\n",
        "print(\"Feature collection created with\", fc.size().getInfo(), \"points.\")"
      ],
      "metadata": {
        "id": "ecqDSO6BV5iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geemap\n",
        "\n",
        "# Create an interactive map\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Define visualization parameters (e.g., color the points red)\n",
        "vis_params = {'color': 'red'}\n",
        "\n",
        "# Add the FeatureCollection to the map\n",
        "Map.addLayer(fc, vis_params, 'Landslide Points')\n",
        "\n",
        "# Center the map view on your points with a zoom level of 8\n",
        "Map.centerObject(fc, 8)\n",
        "\n",
        "# Display the map\n",
        "Map"
      ],
      "metadata": {
        "id": "E22ApzGJ-Ok6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentinel-2 Level-2A (Surface Reflectance)\n",
        "collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "              .filterDate('2022-01-01', '2022-12-31')\n",
        "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)))\n",
        "\n",
        "median_image = collection.median().select(['B2','B3','B4','B8','B11','B12'])  # Blue, Green, Red, NIR\n",
        "\n",
        "median_image = median_image.unmask(0)"
      ],
      "metadata": {
        "id": "WBpbnCzyxWcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate area needed by taking the mean maximum area from all of the landslides"
      ],
      "metadata": {
        "id": "_LY8E4keIwf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define patch size\n",
        "df['Area Maximum'] = pd.to_numeric(df['Area Maximum'], errors='coerce')\n",
        "patch_size_m = np.sqrt(df['Area Maximum'].mean(skipna=True) * 10_000)\n",
        "half_width = patch_size_m / 2\n",
        "print(f\"Suggested patch width: {patch_size_m:.0f} meters\")"
      ],
      "metadata": {
        "id": "XN5U5fmv3rTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of samples to take from each class\n",
        "sample_size = 1250\n",
        "\n",
        "# Filter the collection for each class\n",
        "positives = fc.filter(ee.Filter.eq('label', 1)).limit(sample_size)\n",
        "negatives = fc.filter(ee.Filter.eq('label', 0)).limit(sample_size)\n",
        "\n",
        "# Merge the two limited collections into one\n",
        "fc_limited = positives.merge(negatives)\n",
        "\n",
        "# Shuffle the collection to mix the positive and negative samples\n",
        "fc_limited = fc_limited.randomColumn()\n",
        "fc_limited = fc_limited.sort('random')\n",
        "print(f\"Limited feature collection to {fc_limited.size().getInfo()} points.\")\n",
        "\n",
        "def create_and_tag_patch(feature):\n",
        "    \"\"\"Extracts a patch and sets its ID and label as properties.\"\"\"\n",
        "\n",
        "    # DEFINE THE APPROXIMATE AREA (in meters)\n",
        "    patch_geometry = feature.geometry().buffer(half_width).bounds()\n",
        "\n",
        "    # Store that area as metadata\n",
        "    return median_image.set({\n",
        "        'id': feature.get('id'),\n",
        "        'label': feature.get('label'),\n",
        "        'patch_geometry': patch_geometry\n",
        "    })\n",
        "\n",
        "tagged_image_patches = fc_limited.map(create_and_tag_patch)\n",
        "\n",
        "print(f\"Created a collection of {tagged_image_patches.size().getInfo()} tagged patches.\")"
      ],
      "metadata": {
        "id": "exfKjFNlxx3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making sure that the patches have their labels\n",
        "\n",
        "print(\"Labels of first 5 patches:\", tagged_image_patches.limit(5).aggregate_array('label').getInfo())\n",
        "print(\"Nr of negative and positive samples:\", tagged_image_patches.aggregate_histogram('label').getInfo())"
      ],
      "metadata": {
        "id": "lsi5AjPd2Ynr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create these patches in GEE.\n"
      ],
      "metadata": {
        "id": "ntSAW7rDBnjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GET THE SIZE (from the ImageCollection)\n",
        "num_patches = tagged_image_patches.size().getInfo()\n",
        "\n",
        "# BATCH-FETCH METADATA (from the ImageCollection)\n",
        "print(f\"Fetching metadata for {num_patches} patches...\")\n",
        "\n",
        "# Aggregate directly from the ImageCollection\n",
        "all_ids_client = tagged_image_patches.aggregate_array('id').getInfo()\n",
        "all_labels_client = tagged_image_patches.aggregate_array('label').getInfo()\n",
        "all_geoms_client = tagged_image_patches.aggregate_array('patch_geometry').getInfo()\n",
        "\n",
        "print(\"...Metadata fetched. Starting high-speed task submission.\")"
      ],
      "metadata": {
        "id": "E1PM-PlDQ_Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_patches):\n",
        "\n",
        "    # Get metadata from your local Python lists\n",
        "    patch_id = all_ids_client[i]\n",
        "    patch_label = all_labels_client[i]\n",
        "    patch_geom = all_geoms_client[i]\n",
        "\n",
        "\n",
        "    # Assuming the geometry is a Polygon\n",
        "    clean_geom = ee.Geometry.Polygon(patch_geom['coordinates'])\n",
        "\n",
        "    # Create the filename\n",
        "    filename = f\"patch_id_{patch_id}_label_{patch_label}\"\n",
        "\n",
        "    # Define the export task\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=median_image,\n",
        "        description=f'Export_Patch_id_{patch_id}_index_{i}',\n",
        "        folder='GEE_Landslide_Patches_2',\n",
        "        fileNamePrefix=filename,\n",
        "        region=clean_geom,\n",
        "        dimensions='100x100',\n",
        "        fileFormat='GeoTIFF'\n",
        "    )\n",
        "\n",
        "\n",
        "    if i%25 == 0:\n",
        "      print(f\"Exporting patch {i+1}/{num_patches}...\")\n",
        "\n",
        "    # Start the task\n",
        "    task.start()\n",
        "\n",
        "print(f\"All {num_patches} tasks have been submitted.\")\n",
        "print(\"Monitor their progress in the 'Tasks' tab of the GEE Code Editor.\")"
      ],
      "metadata": {
        "id": "cAAY0akfRFGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing one patch\n",
        "\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "filepath = '/content/drive/MyDrive/GEE_Landslide_Patches/patch_id_1171_label_1.tif'\n",
        "\n",
        "with rasterio.open(filepath) as src:\n",
        "    # Read the red, green, and blue bands into a 3D array\n",
        "    # Note: Sentinel-2 band numbers might be different, e.g., B4, B3, B2 are often bands 4, 3, 2.\n",
        "    # We'll assume the first three bands are the ones we want for simplicity here.\n",
        "    # You may need to adjust the numbers in read([1, 2, 3])\n",
        "    rgb = src.read([1, 2, 3])\n",
        "\n",
        "    # Function to normalize bands for display\n",
        "    def normalize(array):\n",
        "        array_min, array_max = array.min(), array.max()\n",
        "        return ((array - array_min) / (array_max - array_min))\n",
        "\n",
        "    # Normalize each band to the 0-1 range for proper RGB display\n",
        "    red_normalized = normalize(rgb[0])\n",
        "    green_normalized = normalize(rgb[1])\n",
        "    blue_normalized = normalize(rgb[2])\n",
        "\n",
        "    # Stack the bands back together\n",
        "    rgb_normalized = np.dstack((red_normalized, green_normalized, blue_normalized))\n",
        "\n",
        "    # Display the true-color image\n",
        "    plt.imshow(rgb_normalized)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ym4rv8DT6566"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "# The next two big portions is just me playing around and understanding what the fuck I have to do. For the actual ensemble model jump to \"Ensemble model: Random Forest - CNN\"\n",
        "\n",
        "### (I suggest collapsing the titles \"CNN\" and \"Now we try to give our brain a body\" in order not having to scroll too much)\n",
        "----"
      ],
      "metadata": {
        "id": "CtkGBgGFE7TB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "wCDAwwdjFkWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Access data in google drive"
      ],
      "metadata": {
        "id": "Oa0nNbU3Fohk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "ykZTfXX-rYO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "import numpy as np\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/GEE_Landslide_Patches_2'\n",
        "\n",
        "file_pattern = os.path.join(folder_path, \"*.tif\")\n",
        "patch_files = glob.glob(file_pattern)\n",
        "\n",
        "print(f\"Found {len(patch_files)} patch files.\")\n",
        "if patch_files:\n",
        "    print(f\"Example file: {patch_files[0]}\")"
      ],
      "metadata": {
        "id": "wiwFZcH_FtDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create the training data by assigning the image data of each tiff file to our X and the label (which is found in the end of each patch's name, e.g., 'patch_id_123_label_1.tif') to our y."
      ],
      "metadata": {
        "id": "1iGC8LzDsEL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = []  # features\n",
        "y_data = []  # targets\n",
        "skipped_count = 0\n",
        "\n",
        "with rasterio.open(patch_files[5]) as src:\n",
        "    target_shape = src.read().shape\n",
        "print(f\"All patches will be validated against this shape: {target_shape}\")\n",
        "\n",
        "for file_path in patch_files:\n",
        "  try:\n",
        "    # --- Read the image data ---\n",
        "    with rasterio.open(file_path) as src:\n",
        "        image_data = src.read()\n",
        "\n",
        "    # --- FIX 2: Check if this patch matches the target shape ---\n",
        "    if image_data.shape == target_shape:\n",
        "        X_data.append(image_data)\n",
        "\n",
        "        # --- Get the label (only if the data is added) ---\n",
        "        filename = os.path.basename(file_path)\n",
        "        label_str = filename.split('_label_')[1].split('.tif')[0]\n",
        "        y_data.append(int(label_str))\n",
        "    else:\n",
        "        # Skip this file as its shape is different\n",
        "        print(f\"Skipping {file_path}: Shape was {image_data.shape}, expected {target_shape}\")\n",
        "        skipped_count += 1\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading {file_path}: {e}\")\n",
        "    skipped_count += 1\n",
        "\n",
        "# Convert the lists into NumPy arrays for machine learning\n",
        "X_train = np.array(X_data)\n",
        "y_train = np.array(y_data)\n",
        "\n",
        "print(f\"\\nSuccessfully loaded {len(X_train)} patches.\")\n",
        "print(f\"Skipped {skipped_count} patches due to shape mismatch or errors.\")\n",
        "print(f\"Loaded X_train data with shape: {X_train.shape}\")\n",
        "print(f\"Loaded y_train data with shape: {y_train.shape}\")"
      ],
      "metadata": {
        "id": "QrF3jKpbr92-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "N9rWV9QYxOBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "Y0wHeLkGxXA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data for the CNN\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Your data shape is (samples, bands, height, width), e.g., (2000, 6, 100, 100)\n",
        "# Keras's default format is (samples, height, width, bands)\n",
        "# We need to re-order the dimensions.\n",
        "\n",
        "print(f\"Original X_train shape: {X_train.shape}\")\n",
        "X_train_reshaped = np.transpose(X_train, (0, 2, 3, 1))\n",
        "X_test_reshaped = np.transpose(X_test, (0, 2, 3, 1))\n",
        "print(f\"Reshaped X_train shape: {X_train_reshaped.shape}\")\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "# This is crucial for neural network performance\n",
        "max_pixel_value = np.max(X_train_reshaped)\n",
        "print(f\"Max pixel value found: {max_pixel_value}\")\n",
        "\n",
        "X_train_norm = X_train_reshaped.astype('float32') / max_pixel_value\n",
        "X_test_norm = X_test_reshaped.astype('float32') / max_pixel_value\n",
        "\n",
        "# Get the input shape for the model (height, width, bands)\n",
        "input_shape = X_train_norm.shape[1:]\n",
        "print(f\"Model input shape will be: {input_shape}\")"
      ],
      "metadata": {
        "id": "nkC_VcaNypoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # Input Layer\n",
        "    keras.Input(shape=input_shape),\n",
        "\n",
        "    # Convolutional Block 1\n",
        "    # 32 filters, 3x3 kernel size\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    # 64 filters, 3x3 kernel size\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Classifier Head\n",
        "    layers.Flatten(), # Flattens the 3D map to a 1D vector\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dropout(0.5), # Helps prevent overfitting\n",
        "\n",
        "    # Output Layer\n",
        "    # 1 neuron with 'sigmoid' activation for a 0-to-1 probability\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "8gv76174yzpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# FIX: Use a much smaller learning rate to prevent 'nan'\n",
        "optimizer = Adam(learning_rate=0.0001)  # Default is 0.001\n",
        "\n",
        "# We use 'binary_crossentropy' because this is a 2-class (0 or 1) problem\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fx-C6r6Fy6Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    X_train_norm,          # Use normalized, reshaped training data\n",
        "    y_train,               # Training labels\n",
        "    batch_size=32,\n",
        "    epochs=15,             # You can increase this if needed\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "mWi2xFAky_d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Plot Training & Validation Accuracy ---\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1) # (1 row, 2 columns, plot 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# --- 2. Plot Training & Validation Loss ---\n",
        "plt.subplot(1, 2, 2) # (1 row, 2 columns, plot 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# --- 3. Show the plots ---\n",
        "plt.tight_layout() # Adjusts plots to prevent overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "atj5wbZEzl2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- 1. Get the model's predictions for the entire test set ---\n",
        "# The output is a list of raw probabilities (e.g., 0.05, 0.92, etc.)\n",
        "y_pred_proba = model.predict(X_test_norm)\n",
        "\n",
        "print(\"--- Evaluating Model on Unseen Test Data ---\\n\")\n",
        "print(f\"Displaying predictions for the first 20 patches:\\n\")\n",
        "\n",
        "# --- 2. Loop through a sample of predictions and display them ---\n",
        "for i in range(min(20, len(y_test))): # Show up to 20 predictions\n",
        "\n",
        "    # Get the raw probability from the model's output\n",
        "    probability = y_pred_proba[i][0]\n",
        "\n",
        "    # Convert to a percentage\n",
        "    susceptibility_percent = probability * 100\n",
        "\n",
        "    # Get the actual, correct label\n",
        "    actual_label = y_test[i]\n",
        "\n",
        "    # Print a clear, formatted result\n",
        "    print(f\"Patch {i+1}: Susceptibility = {susceptibility_percent:.2f}%  (Actual Label: {actual_label})\")\n",
        "\n",
        "\n",
        "# --- 3. Get the final, overall accuracy on the test set ---\n",
        "final_loss, final_accuracy = model.evaluate(X_test_norm, y_test, verbose=0)\n",
        "print(f\"\\n-------------------------------------------------\")\n",
        "print(f\"Final Model Accuracy on Test Set: {final_accuracy * 100:.2f}%\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "\n",
        "\n",
        "# --- 4. (Optional) Show a more detailed performance report ---\n",
        "# We convert probabilities to binary predictions (0 or 1) using a 0.5 threshold\n",
        "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nDetailed Classification Report:\\n\")\n",
        "# This shows precision, recall, and f1-score for both classes (0 and 1)\n",
        "print(classification_report(y_test, y_pred_binary, target_names=['No Landslide (0)', 'Landslide (1)']))"
      ],
      "metadata": {
        "id": "AzK7b9dMlGzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we try to give our brain a body"
      ],
      "metadata": {
        "id": "UvZ-oyvnlrOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('landslide_susceptibility_model.keras')"
      ],
      "metadata": {
        "id": "PqJhGLf6lgCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code takes in a really small patch, just like the ones in our dataset, and makes a prediction. I will later create code that caan take in a larger area and make a susceptibility map out of it. This larger image needs to have the exaact same bands, needs to be noralized the exact same way, the only thing that can ddiffer is the overall size, i.e. it could be 5000x5000 instead of 1000x1000 like our patches."
      ],
      "metadata": {
        "id": "VU6ri3zNo-rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # <-- Make sure this is imported\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MODEL_FILE = 'landslide_susceptibility_model.keras'\n",
        "PATCH_FILE = '/content/drive/MyDrive/GEE_Landslide_Patches_2/patch_id_913_label_1.tif'\n",
        "\n",
        "# --- You MUST get this value from your training script ---\n",
        "MAX_PIXEL_VALUE = 8704.0\n",
        "\n",
        "PATCH_SIZE = 100\n",
        "\n",
        "# --- 2. LOAD MODEL ---\n",
        "print(\"Loading model...\")\n",
        "model = keras.models.load_model(MODEL_FILE)\n",
        "\n",
        "print(f\"Loading patch: {PATCH_FILE}\")\n",
        "with rasterio.open(PATCH_FILE) as src:\n",
        "    # Read all band data\n",
        "    patch_data = src.read() # Shape (bands, 100, 100)\n",
        "\n",
        "    # Check if patch is the correct size\n",
        "    if patch_data.shape[1] != PATCH_SIZE or patch_data.shape[2] != PATCH_SIZE:\n",
        "        print(f\"Error: Patch is not {PATCH_SIZE}x{PATCH_SIZE}. Shape: {patch_data.shape}\")\n",
        "    else:\n",
        "\n",
        "        # --- 3. PRE-PROCESS THE PATCH (for the model) ---\n",
        "\n",
        "        # (bands, h, w) -> (h, w, bands)\n",
        "        patch_transposed = np.transpose(patch_data, (1, 2, 0))\n",
        "        # Normalize\n",
        "        patch_norm = patch_transposed.astype('float32') / MAX_PIXEL_VALUE\n",
        "        # Add batch dimension: (h, w, bands) -> (1, h, w, bands)\n",
        "        patch_batch = np.expand_dims(patch_norm, axis=0)\n",
        "\n",
        "        # --- 4. PREDICT ---\n",
        "        # Get the raw probability (0.0 to 1.0)\n",
        "        probability = model.predict(patch_batch, verbose=0)[0][0]\n",
        "        susceptibility_percent = probability * 100\n",
        "\n",
        "        print(f\"Model Prediction: {susceptibility_percent:.2f}% Susceptible\")\n",
        "\n",
        "        # --- 5. VISUALIZE THE PATCH (True Color) ---\n",
        "\n",
        "        # Helper function to normalize bands for 0-1 display\n",
        "        def normalize(array):\n",
        "            array_min, array_max = np.nanmin(array), np.nanmax(array)\n",
        "            return ((array - array_min) / (array_max - array_min))\n",
        "\n",
        "        # Normalize the first 3 bands (assuming Blue, Green, Red)\n",
        "        blue_norm = normalize(patch_data[0])\n",
        "        green_norm = normalize(patch_data[1])\n",
        "        red_norm = normalize(patch_data[2])\n",
        "\n",
        "        # Stack for plotting: (h, w, channels)\n",
        "        rgb_image = np.dstack((red_norm, green_norm, blue_norm))\n",
        "\n",
        "        # --- 6. PLOT THE IMAGE WITH THE PREDICTION ---\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        plt.imshow(rgb_image)\n",
        "        plt.title(f\"Prediction: {susceptibility_percent:.2f}% Susceptible\", fontsize=16)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "TphrP1D_nzUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the code for the susceptibility map, I did not yet try it out on a larger area."
      ],
      "metadata": {
        "id": "Saml4RP3pgua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MODEL_FILE = 'landslide_susceptibility_model.keras'\n",
        "NEW_IMAGE_FILE = '/content/drive/MyDrive/GEE_Landslide_Patches_2/patch_id_913_label_1.tif'\n",
        "OUTPUT_MAP_FILE = 'susceptibility_map.tif'\n",
        "\n",
        "# --- You MUST get this value from your training script ---\n",
        "# This is the max value you used to normalize your data\n",
        "MAX_PIXEL_VALUE = 8704.0  # Example value, REPLACE THIS\n",
        "\n",
        "PATCH_SIZE = 100\n",
        "\n",
        "# --- 2. LOAD MODEL AND DATA ---\n",
        "print(\"Loading model...\")\n",
        "model = keras.models.load_model(MODEL_FILE)\n",
        "\n",
        "print(f\"Loading new image: {NEW_IMAGE_FILE}\")\n",
        "with rasterio.open(NEW_IMAGE_FILE) as src:\n",
        "    # Read all band data\n",
        "    image_data = src.read()\n",
        "    # Get the geospatial metadata\n",
        "    profile = src.profile\n",
        "\n",
        "    # Create an empty array to store the susceptibility \"heat map\"\n",
        "    # We use float32 to store probabilities (e.g., 0.92)\n",
        "    susceptibility_map = np.zeros((src.height, src.width), dtype='float32')\n",
        "\n",
        "    print(\"Running susceptibility scan...\")\n",
        "    # --- 3. \"SLIDING WINDOW\" PREDICTION ---\n",
        "    # We loop over the image in 100x100 blocks\n",
        "\n",
        "    # Calculate how many steps we need in each direction\n",
        "    steps_y = math.ceil(src.height / PATCH_SIZE)\n",
        "    steps_x = math.ceil(src.width / PATCH_SIZE)\n",
        "\n",
        "    for y in range(steps_y):\n",
        "        for x in range(steps_x):\n",
        "            # Define the window\n",
        "            y_start = y * PATCH_SIZE\n",
        "            x_start = x * PATCH_SIZE\n",
        "\n",
        "            # Ensure the patch doesn't go out of bounds\n",
        "            y_end = min(y_start + PATCH_SIZE, src.height)\n",
        "            x_end = min(x_start + PATCH_SIZE, src.width)\n",
        "\n",
        "            # Extract the patch\n",
        "            patch = image_data[:, y_start:y_end, x_start:x_end]\n",
        "\n",
        "            # Skip if patch is not the full 100x100 size (e.g., at the image edge)\n",
        "            if patch.shape[1] != PATCH_SIZE or patch.shape[2] != PATCH_SIZE:\n",
        "                continue\n",
        "\n",
        "            # --- 4. PRE-PROCESS THE PATCH (CRITICAL) ---\n",
        "            # This must exactly match your training code\n",
        "\n",
        "            # (bands, h, w) -> (h, w, bands)\n",
        "            patch_transposed = np.transpose(patch, (1, 2, 0))\n",
        "            # Normalize\n",
        "            patch_norm = patch_transposed.astype('float32') / MAX_PIXEL_VALUE\n",
        "            # Add batch dimension: (h, w, bands) -> (1, h, w, bands)\n",
        "            patch_batch = np.expand_dims(patch_norm, axis=0)\n",
        "\n",
        "            # --- 5. PREDICT ---\n",
        "            # Get the raw probability (0.0 to 1.0)\n",
        "            probability = model.predict(patch_batch, verbose=0)[0][0]\n",
        "\n",
        "            # --- 6. FILL THE MAP ---\n",
        "            # \"Paint\" this probability onto the output map\n",
        "            susceptibility_map[y_start:y_end, x_start:x_end] = probability\n",
        "\n",
        "    print(\"Scan complete. Saving map...\")\n",
        "\n",
        "# --- 7. SAVE THE FINAL \"HEAT MAP\" ---\n",
        "# We update the metadata to save a 1-band (float) image\n",
        "profile.update(\n",
        "    dtype='float32',\n",
        "    count=1,  # We are saving 1 band (the probability)\n",
        "    driver='GTiff'\n",
        ")\n",
        "\n",
        "with rasterio.open(OUTPUT_MAP_FILE, 'w', **profile) as dst:\n",
        "    dst.write(susceptibility_map, 1) # Write the map to the first band\n",
        "\n",
        "print(f\"Success! Susceptibility map saved to: {OUTPUT_MAP_FILE}\")"
      ],
      "metadata": {
        "id": "ETN8yh7blg1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "OUTPUT_MAP_FILE = 'susceptibility_map.tif'\n",
        "\n",
        "print(f\"Loading map: {OUTPUT_MAP_FILE}\")\n",
        "\n",
        "with rasterio.open(OUTPUT_MAP_FILE) as src:\n",
        "    # Read the first (and only) band\n",
        "    susceptibility_data = src.read(1)\n",
        "\n",
        "    # Replace 0 values (no data/padding) with 'nan' so they are transparent\n",
        "    susceptibility_data[susceptibility_data == 0] = np.nan\n",
        "\n",
        "    print(\"Displaying map...\")\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Use 'imshow' to display the 2D array as an image\n",
        "    # We use a color map ('RdYlGn_r') where Red = High, Green = Low\n",
        "    img = plt.imshow(susceptibility_data, cmap='RdYlGn_r',\n",
        "                     vmin=0.0, vmax=1.0)\n",
        "\n",
        "    plt.title(\"Landslide Susceptibility Map\")\n",
        "    plt.xlabel(\"X Pixels\")\n",
        "    plt.ylabel(\"Y Pixels\")\n",
        "\n",
        "    # Add a color bar to show what the values mean\n",
        "    cbar = plt.colorbar(img, fraction=0.046, pad=0.04)\n",
        "    cbar.set_label('Susceptibility (0.0 = Low, 1.0 = High)')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4ZMkVFgMmX36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble model: Random forest - CNN\n",
        "This part of the code creates a multi-modal model that is able to take in patches and numerical data like slop, landcover etc."
      ],
      "metadata": {
        "id": "x-tJI7Nppxx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading the data"
      ],
      "metadata": {
        "id": "hdajkRfyrEQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads two types of data: .tif files which are patches created around the long-lat points in our numerical datasets, and some geological and topographical data for each point. In the end, we align these two types of data to be able to feed it into the model. We create the following data:\n",
        "- X_images_list: All the pixel data from the patches.\n",
        "\n",
        "- X_numerical_list: All the corresponding numerical features (slope, curvature, etc.) from the CSV.\n",
        "\n",
        "- y_labels_list: The labels (0 or 1) that align with both.\n",
        "\n",
        "Then we convert these lists into numpy arrays and normalize them for the machine learning model by transposing them to (samples, h, w, bands) and dividing them by MAX_PIXEL_VALUE.\n",
        "\n",
        "In the end, we create the train-test split already."
      ],
      "metadata": {
        "id": "zeuQgzgy9NV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import rasterio\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Numerical Data\n",
        "csv_path = '/content/drive/MyDrive/GEOG761 Machine Learning for Remote Sensing/Group project landslide susceptibility/landslides_with_variables_fixed1.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Load Image Patches and Align\n",
        "folder_path = '/content/drive/MyDrive/GEE_Landslide_Patches_2'\n",
        "patch_files = glob.glob(folder_path + \"/*.tif\")\n",
        "\n",
        "X_images_list = []\n",
        "X_numerical_list = []\n",
        "y_labels_list = []\n",
        "\n",
        "print(f\"Found {len(patch_files)} files. Aligning with CSV...\")\n",
        "\n",
        "for file_path in patch_files:\n",
        "    filename = os.path.basename(file_path)\n",
        "\n",
        "    #  Extract ID and Label from filename\n",
        "    # e.g., 'patch_id_89_label_1.tif'\n",
        "    parts = filename.split('_')\n",
        "    patch_id = int(parts[2]) # Get the '89'\n",
        "    patch_label = int(parts[4].split('.tif')[0]) # Get the '1'\n",
        "\n",
        "    # Find the matching row in the CSV\n",
        "    row = df[df['ID'] == patch_id]\n",
        "\n",
        "    if not row.empty:\n",
        "        # Add the numerical data\n",
        "        numerical_features = row[['CURVATURE', 'TWI', 'SLOPE_deg', 'DEM', 'LANDCOVER_CODE', 'ASPECT_sin', 'ASPECT_cos']].values[0]\n",
        "        X_numerical_list.append(numerical_features)\n",
        "\n",
        "        # Add the label\n",
        "        y_labels_list.append(patch_label)\n",
        "\n",
        "        # Add the image data\n",
        "        with rasterio.open(file_path) as src:\n",
        "            X_images_list.append(src.read())\n",
        "\n",
        "# Convert to NumPy Arrays\n",
        "X_images = np.array(X_images_list)\n",
        "X_numerical = np.array(X_numerical_list)\n",
        "y = np.array(y_labels_list)\n",
        "\n",
        "# -- Pre-process --\n",
        "# Images: Transpose and normalize as before\n",
        "X_images_norm = np.transpose(X_images, (0, 2, 3, 1)) / MAX_PIXEL_VALUE\n",
        "\n",
        "# Numerical: Scale the data\n",
        "# This scales numbers (like slope) to be in a similar range (e.g., -1 to 1)\n",
        "scaler = StandardScaler()\n",
        "X_numerical_norm = scaler.fit_transform(X_numerical)\n",
        "\n",
        "print(f\"Image data shape: {X_images_norm.shape}\")\n",
        "print(f\"Numerical data shape: {X_numerical_norm.shape}\")\n",
        "print(f\"Label data shape: {y.shape}\")\n",
        "\n",
        "# Split all three datasets together\n",
        "# We need to split twice to explicitely define the validation set because a random forest model,\n",
        "# as opposed to a CNN, does not have a built-in validation split\n",
        "\n",
        "# First split: (Train + Val) and Test (80% / 20%)\n",
        "X_img_train_val, X_img_test, y_train_val, y_test = train_test_split(\n",
        "    X_images_norm, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_num_train_val, X_num_test, _, _ = train_test_split(\n",
        "    X_numerical_norm, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: (Train) and (Val) (75% of 80% = 60% / 25% of 80% = 20%)\n",
        "X_img_train, X_img_val, y_train, y_val = train_test_split(\n",
        "    X_img_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "X_num_train, X_num_val, _, _ = train_test_split(\n",
        "    X_num_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "print(f\"Train shapes: {X_img_train.shape}, {X_num_train.shape}, {y_train.shape}\")\n",
        "print(f\"Val shapes:   {X_img_val.shape}, {X_num_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test shapes:  {X_img_test.shape}, {X_num_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "-aiD85FfrDB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we build and train the CNN first."
      ],
      "metadata": {
        "id": "XfDIrKcW-kSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "image_input_shape = X_img_train.shape[1:]\n",
        "input_image = keras.Input(shape=image_input_shape)\n",
        "cnn_branch = layers.Conv2D(32, (3, 3), activation='relu')(input_image)\n",
        "cnn_branch = layers.MaxPooling2D((2, 2))(cnn_branch)\n",
        "cnn_branch = layers.Conv2D(64, (3, 3), activation='relu')(cnn_branch)\n",
        "cnn_branch = layers.MaxPooling2D((2, 2))(cnn_branch)\n",
        "cnn_branch = layers.Flatten()(cnn_branch)\n",
        "cnn_branch = layers.Dense(64, activation='relu')(cnn_branch)\n",
        "cnn_output = layers.Dense(1, activation='sigmoid')(cnn_branch)\n",
        "\n",
        "cnn_model = keras.Model(inputs=input_image, outputs=cnn_output)\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training CNN Model ---\")\n",
        "cnn_model.fit(\n",
        "    X_img_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_img_val, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "ldAtMVhW-eZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the simple random forest."
      ],
      "metadata": {
        "id": "oilLK-TE-zYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"\\n--- Training Random Forest Model ---\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_num_train, y_train)\n",
        "\n",
        "# Check validation accuracy\n",
        "val_accuracy = rf_model.score(X_num_train, y_train)\n",
        "print(f\"Random Forest Validation Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "vb1sK6wL-xa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble model combined by logistic regression"
      ],
      "metadata": {
        "id": "XZ_SrX8JBjEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step, we will stack both of the models. We will use the validation set to train a *new* very simple model (I chose logistic regression, it just needs to learn how to best combine the predictions from the two base models). The logistic regression model learns how much to trust each base model's prediction.\n",
        "\n",
        "It looks like this:\n",
        "\n",
        "It gets the inputs from both models:\n",
        "\n",
        "- The CNN: \"Based on the image, I'm 90% sure this is a landslide.\"\n",
        "\n",
        "- The Random Forest: \"Based on the numbers, I'm only 60% sure.\"\n",
        "\n",
        "The logistic regression model's job is to take those two inputs (90% and 60%) and make the final decision. By training it on the validation data, it learns which model is more reliable in which situations.\n",
        "\n",
        "For example, it might learn: \"The CNN is usually overconfident, so I'll trust the Random Forest more.\" Or it might learn: \"When both models agree, they are almost always right, but when they disagree, I should trust the CNN.\"\n",
        "\n",
        "It learns the optimal weights or rules to combine the two predictions into a single, more accurate final prediction."
      ],
      "metadata": {
        "id": "bHkScjwt-7dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Get predictions from base models on the VALIDATION set\n",
        "print(\"\\n--- Training Meta-Model ---\")\n",
        "cnn_val_probs = cnn_model.predict(X_img_val)\n",
        "rf_val_probs = rf_model.predict_proba(X_num_val)[:, 1] # Get prob of class '1'\n",
        "\n",
        "# 2. Stack these predictions into a new feature array\n",
        "# Shape will be (num_val_samples, 2)\n",
        "X_val_stacked = np.c_[cnn_val_probs, rf_val_probs]\n",
        "\n",
        "# 3. Train the meta-model (Logistic Regression is perfect for this)\n",
        "# It learns the best \"weight\" for the CNN prob vs. the RF prob\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(X_val_stacked, y_val)\n",
        "\n",
        "print(\"Meta-Model trained.\")"
      ],
      "metadata": {
        "id": "HYGElKNH_-Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, we will evaluate the final hybrid model on the test set."
      ],
      "metadata": {
        "id": "wEHFR8ouAEVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get predictions from base models on the TEST set\n",
        "print(\"\\n--- Final Evaluation on Test Set ---\")\n",
        "cnn_test_probs = cnn_model.predict(X_img_test)\n",
        "rf_test_probs = rf_model.predict_proba(X_num_test)[:, 1]\n",
        "\n",
        "# 2. Stack them just like before\n",
        "X_test_stacked = np.c_[cnn_test_probs, rf_test_probs]\n",
        "\n",
        "# 3. Get the final hybrid prediction from the meta-model\n",
        "hybrid_predictions = meta_model.predict(X_test_stacked)\n",
        "\n",
        "# 4. Report the results\n",
        "final_accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "print(f\"\\nFinal HYBRID Model Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "print(\"\\nHybrid Model Classification Report:\")\n",
        "print(classification_report(y_test, hybrid_predictions))"
      ],
      "metadata": {
        "id": "4r1v1riZADru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}