{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sisn749/Landslide_Susceptibility_GEOG761/blob/main/Ensemble_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhQn06w-xGEf"
      },
      "source": [
        "# Extract patches\n",
        "\n",
        "NO NEED TO RUN THIS IF YOU ALREADY HAVE THE DATASET;  JUMP TO \"ENSEMBLE MODEL ...\" IF YOU NEED TO RERUN THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-dLRZ83DV9e"
      },
      "source": [
        "-------\n",
        "\n",
        "\n",
        "How it works:\n",
        "\n",
        "- Sentinel-2 SR provides L2A reflectance at 10 m.\n",
        "\n",
        "- The .median() composite merges cloud-free pixels from 2019–2022.\n",
        "\n",
        "- Each point.buffer(464 m) yields a ~928 m window around the coordinate.\n",
        "\n",
        "- Patches are exported to Google Drive → “GEE_Landslide_Patches” folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpGem5uixJNw"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='clara-geog761-tryout-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36revHaS9-l5"
      },
      "source": [
        "Now, we will transform the numerical long-lat  into GEE points that are georeferenced. The cell after this visualizes these points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OppF2g-BxgQx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/GEOG761 Machine Learning for Remote Sensing/Group project landslide susceptibility/landslides_with_variables_fixed1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecqDSO6BV5iC"
      },
      "outputs": [],
      "source": [
        "# Convert to ee.FeatureCollection\n",
        "def row_to_feature(row):\n",
        "    geom = ee.Geometry.Point(float(row['Longitude']), float(row['Latitude']))\n",
        "    # Make sure 'Valid Landslide' is integer and has no nulls for filtering\n",
        "    label = row['Valid Landslide']\n",
        "    if pd.notna(label):\n",
        "        return ee.Feature(geom, {'id': int(row.name), 'label': int(label)})\n",
        "    else:\n",
        "      print(\"AAAAAAAAAAAAAA\")\n",
        "    return None\n",
        "\n",
        "features = [row_to_feature(r) for _, r in df.iterrows()]\n",
        "features = [f for f in features if f is not None] # Remove null features\n",
        "fc = ee.FeatureCollection(features)\n",
        "\n",
        "print(\"Feature collection created with\", fc.size().getInfo(), \"points.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E22ApzGJ-Ok6"
      },
      "outputs": [],
      "source": [
        "# Visualizing all of our datapoint on a GEE map\n",
        "\n",
        "import geemap\n",
        "\n",
        "Map = geemap.Map()\n",
        "vis_params = {'color': 'red'}\n",
        "Map.addLayer(fc, vis_params, 'Landslide Points')\n",
        "Map.centerObject(fc, 8)\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBpbnCzyxWcv"
      },
      "outputs": [],
      "source": [
        "# Sentinel-2 Level-2A (Surface reflectance)\n",
        "collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "              .filterDate('2022-01-01', '2022-12-31')\n",
        "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)))\n",
        "\n",
        "median_image = collection.median().select(['B2','B3','B4','B8','B11','B12'])\n",
        "\n",
        "median_image = median_image.unmask(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LY8E4keIwf_"
      },
      "source": [
        "Calculate area needed around each datapoint to create patches by taking the mean maximum area from all of the landslides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN5U5fmv3rTk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define patch size\n",
        "df['Area Maximum'] = pd.to_numeric(df['Area Maximum'], errors='coerce')\n",
        "patch_size_m = np.sqrt(df['Area Maximum'].mean(skipna=True) * 10_000)\n",
        "half_width = patch_size_m / 2\n",
        "print(f\"Suggested patch width: {patch_size_m:.0f} meters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exfKjFNlxx3h"
      },
      "outputs": [],
      "source": [
        "# Define the number of samples to take from each class\n",
        "sample_size = 1250\n",
        "\n",
        "# Filter the collection for each class\n",
        "positives = fc.filter(ee.Filter.eq('label', 1)).limit(sample_size)\n",
        "negatives = fc.filter(ee.Filter.eq('label', 0)).limit(sample_size)\n",
        "\n",
        "# Merge the two limited collections into one\n",
        "fc_limited = positives.merge(negatives)\n",
        "\n",
        "# Shuffle the collection to mix the positive and negative samples\n",
        "fc_limited = fc_limited.randomColumn()\n",
        "fc_limited = fc_limited.sort('random')\n",
        "print(f\"Limited feature collection to {fc_limited.size().getInfo()} points.\")\n",
        "\n",
        "# The following function extracts a patch and sets its ID and label as properties\n",
        "def create_and_tag_patch(feature):\n",
        "\n",
        "    # Define the approximate area (in meters)\n",
        "    patch_geometry = feature.geometry().buffer(half_width).bounds()\n",
        "\n",
        "    # Store that area as metadata\n",
        "    return median_image.set({\n",
        "        'id': feature.get('id'),\n",
        "        'label': feature.get('label'),\n",
        "        'patch_geometry': patch_geometry\n",
        "    })\n",
        "\n",
        "tagged_image_patches = fc_limited.map(create_and_tag_patch)\n",
        "\n",
        "print(f\"Created a collection of {tagged_image_patches.size().getInfo()} tagged patches.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsi5AjPd2Ynr"
      },
      "outputs": [],
      "source": [
        "# Making sure that the patches have their labels\n",
        "\n",
        "print(\"Labels of first 5 patches:\", tagged_image_patches.limit(5).aggregate_array('label').getInfo())\n",
        "print(\"Nr of negative and positive samples:\", tagged_image_patches.aggregate_histogram('label').getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntSAW7rDBnjg"
      },
      "source": [
        "Now we will create these patches in GEE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1PM-PlDQ_Is"
      },
      "outputs": [],
      "source": [
        "# Get the size from the ImageCollection\n",
        "num_patches = tagged_image_patches.size().getInfo()\n",
        "\n",
        "# Batch-fetch metadata by aggregating directly from the ImageCollection\n",
        "all_ids_client = tagged_image_patches.aggregate_array('id').getInfo()\n",
        "all_labels_client = tagged_image_patches.aggregate_array('label').getInfo()\n",
        "all_geoms_client = tagged_image_patches.aggregate_array('patch_geometry').getInfo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAAY0akfRFGg"
      },
      "outputs": [],
      "source": [
        "# This function creates a task for each patch\n",
        "\n",
        "for i in range(num_patches):\n",
        "\n",
        "    patch_id = all_ids_client[i]\n",
        "    patch_label = all_labels_client[i]\n",
        "    patch_geom = all_geoms_client[i]\n",
        "\n",
        "    clean_geom = ee.Geometry.Polygon(patch_geom['coordinates'])\n",
        "    filename = f\"patch_id_{patch_id}_label_{patch_label}\"\n",
        "\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=median_image,\n",
        "        description=f'Export_Patch_id_{patch_id}_index_{i}',\n",
        "        folder='GEE_Landslide_Patches_2',\n",
        "        fileNamePrefix=filename,\n",
        "        region=clean_geom,\n",
        "        dimensions='100x100',\n",
        "        fileFormat='GeoTIFF'\n",
        "    )\n",
        "\n",
        "\n",
        "    if i%25 == 0:\n",
        "      print(f\"Exporting patch {i+1}/{num_patches}...\")\n",
        "\n",
        "    task.start()\n",
        "\n",
        "print(f\"All {num_patches} tasks have been submitted.\")\n",
        "print(\"Monitor their progress in the 'Tasks' tab of the GEE Code Editor.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym4rv8DT6566"
      },
      "outputs": [],
      "source": [
        "# Visualizing one patch\n",
        "\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "filepath = '/content/drive/MyDrive/GEE_Landslide_Patches/patch_id_1171_label_1.tif'\n",
        "\n",
        "with rasterio.open(filepath) as src:\n",
        "    # Read the red, green, and blue bands into a 3D array\n",
        "    # Note: Sentinel-2 band numbers might be different, e.g., B4, B3, B2 are often bands 4, 3, 2.\n",
        "    # We'll assume the first three bands are the ones we want for simplicity here.\n",
        "    rgb = src.read([1, 2, 3])\n",
        "\n",
        "    # Function to normalize bands for display\n",
        "    def normalize(array):\n",
        "        array_min, array_max = array.min(), array.max()\n",
        "        return ((array - array_min) / (array_max - array_min))\n",
        "\n",
        "    # Normalize each band to the 0-1 range for proper RGB display\n",
        "    red_normalized = normalize(rgb[0])\n",
        "    green_normalized = normalize(rgb[1])\n",
        "    blue_normalized = normalize(rgb[2])\n",
        "\n",
        "    # Stack the bands back together\n",
        "    rgb_normalized = np.dstack((red_normalized, green_normalized, blue_normalized))\n",
        "\n",
        "    # Display the true-color image\n",
        "    plt.imshow(rgb_normalized)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tJI7Nppxx_"
      },
      "source": [
        "# Ensemble model: Random forest - CNN\n",
        "This part of the code creates a multi-modal model that is able to take in patches and numerical data like slope, landcover etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdajkRfyrEQh"
      },
      "source": [
        "1. Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeuQgzgy9NV4"
      },
      "source": [
        "This code loads two types of data: .tif files which are patches created around the long-lat points in our numerical datasets, and some geological and topographical data for each point. In the end, we align these two types of data to be able to feed it into the model. We create the following data:\n",
        "- X_images_list: All the pixel data from the patches.\n",
        "\n",
        "- X_numerical_list: All the corresponding numerical features (slope, curvature, etc.) from the CSV.\n",
        "\n",
        "- y_labels_list: The labels (0 or 1) that align with both.\n",
        "\n",
        "Then we convert these lists into numpy arrays and normalize them for the machine learning model by transposing them to (samples, h, w, bands) and dividing them by MAX_PIXEL_VALUE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this if you need to install rasterio\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aiD85FfrDB5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the numerical data\n",
        "# Make sure to change the path to where the dataset is stored on your own device \n",
        "csv_path = '/content/drive/MyDrive/GEOG761 Machine Learning for Remote Sensing/Group project landslide susceptibility/landslides_with_variables_fixed1.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Load image patches and align\n",
        "# Make sure to change the path to where the dataset is stored on your own device \n",
        "folder_path = '/content/drive/MyDrive/GEE_Landslide_Patches_2'\n",
        "patch_files = glob.glob(folder_path + \"/*.tif\")\n",
        "\n",
        "X_images_list = []\n",
        "X_numerical_list = []\n",
        "y_labels_list = []\n",
        "\n",
        "print(f\"Found {len(patch_files)} files. Aligning with CSV...\")\n",
        "\n",
        "for file_path in patch_files:\n",
        "    filename = os.path.basename(file_path)\n",
        "\n",
        "    #  Extract ID and Label from filename\n",
        "    # e.g., 'patch_id_89_label_1.tif'\n",
        "    parts = filename.split('_')\n",
        "    patch_id = int(parts[2]) # Get the '89'\n",
        "    patch_label = int(parts[4].split('.tif')[0]) # Get the '1'\n",
        "\n",
        "    # Find the matching row in the CSV\n",
        "    row = df[df['ID'] == patch_id]\n",
        "\n",
        "    if not row.empty:\n",
        "        # Add the numerical data\n",
        "        numerical_features = row[['CURVATURE', 'TWI', 'SLOPE_deg', 'DEM', 'LANDCOVER_CODE', 'ASPECT_sin', 'ASPECT_cos']].values[0]\n",
        "        X_numerical_list.append(numerical_features)\n",
        "\n",
        "        # Add the label\n",
        "        y_labels_list.append(patch_label)\n",
        "\n",
        "        # Add the image data\n",
        "        with rasterio.open(file_path) as src:\n",
        "            X_images_list.append(src.read())\n",
        "\n",
        "# Convert to NumPy Arrays\n",
        "X_images = np.array(X_images_list)\n",
        "X_numerical = np.array(X_numerical_list)\n",
        "y = np.array(y_labels_list)\n",
        "MAX_PIXEL_VALUE = np.max(X_images)\n",
        "print(MAX_PIXEL_VALUE)\n",
        "\n",
        "# -- Pre-process --\n",
        "# Images: Transpose and normalize as before\n",
        "X_images_norm = np.transpose(X_images, (0, 2, 3, 1)) / MAX_PIXEL_VALUE\n",
        "\n",
        "# Numerical: Scale the data\n",
        "# This transforms the numerical data so it has a mean of 0 and a standard deviation of 1\n",
        "scaler = StandardScaler()\n",
        "X_numerical_norm = scaler.fit_transform(X_numerical)\n",
        "\n",
        "print(f\"Image data shape: {X_images_norm.shape}\")\n",
        "print(f\"Numerical data shape: {X_numerical_norm.shape}\")\n",
        "print(f\"Label data shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split all three datasets together\n",
        "# We need to split twice to explicitely define the validation set because a random forest model,\n",
        "# as opposed to a CNN, does not have a built-in validation split\n",
        "\n",
        "# First split: (Train + Val) and Test (80% / 20%)\n",
        "X_img_train_val, X_img_test, y_train_val, y_test = train_test_split(\n",
        "    X_images_norm, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_num_train_val, X_num_test, _, _ = train_test_split(\n",
        "    X_numerical_norm, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: (Train) and (Val) (75% of 80% = 60% / 25% of 80% = 20%)\n",
        "X_img_train, X_img_val, y_train, y_val = train_test_split(\n",
        "    X_img_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "X_num_train, X_num_val, _, _ = train_test_split(\n",
        "    X_num_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "print(f\"Train shapes: {X_img_train.shape}, {X_num_train.shape}, {y_train.shape}\")\n",
        "print(f\"Val shapes:   {X_img_val.shape}, {X_num_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test shapes:  {X_img_test.shape}, {X_num_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfDIrKcW-kSv"
      },
      "source": [
        "Now we build and train the CNN first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldAtMVhW-eZD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "image_input_shape = X_img_train.shape[1:]\n",
        "input_image = keras.Input(shape=image_input_shape)\n",
        "cnn_branch = layers.Conv2D(32, (3, 3), activation='relu')(input_image)\n",
        "cnn_branch = layers.MaxPooling2D((2, 2))(cnn_branch)\n",
        "cnn_branch = layers.Conv2D(64, (3, 3), activation='relu')(cnn_branch)\n",
        "cnn_branch = layers.MaxPooling2D((2, 2))(cnn_branch)\n",
        "cnn_branch = layers.Flatten()(cnn_branch)\n",
        "cnn_branch = layers.Dense(64, activation='relu')(cnn_branch)\n",
        "cnn_output = layers.Dense(1, activation='sigmoid')(cnn_branch)\n",
        "\n",
        "cnn_model = keras.Model(inputs=input_image, outputs=cnn_output)\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training CNN Model ---\")\n",
        "cnn_model.fit(\n",
        "    X_img_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_img_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oilLK-TE-zYd"
      },
      "source": [
        "Now the simple random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb1sK6wL-xa2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"\\n--- Training Random Forest Model ---\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_num_train, y_train)\n",
        "\n",
        "# Check validation accuracy\n",
        "val_accuracy = rf_model.score(X_num_train, y_train)\n",
        "print(f\"Random Forest Validation Accuracy: {val_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ_SrX8JBjEU"
      },
      "source": [
        "## Ensemble model combined by logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHkScjwt-7dr"
      },
      "source": [
        "In the next step, we will stack both of the models. We will use the validation set to train a *new* very simple model (I chose logistic regression, it just needs to learn how to best combine the predictions from the two base models). The logistic regression model learns how much to trust each base model's prediction.\n",
        "\n",
        "It looks like this:\n",
        "\n",
        "It gets the inputs from both models:\n",
        "\n",
        "- The CNN: \"Based on the image, I'm 90% sure this is a landslide.\"\n",
        "\n",
        "- The Random Forest: \"Based on the numbers, I'm only 60% sure.\"\n",
        "\n",
        "The logistic regression model's job is to take those two inputs (90% and 60%) and make the final decision. By training it on the validation data, it learns which model is more reliable in which situations.\n",
        "\n",
        "For example, it might learn: \"The CNN is usually overconfident, so I'll trust the Random Forest more.\" Or it might learn: \"When both models agree, they are almost always right, but when they disagree, I should trust the CNN.\"\n",
        "\n",
        "It learns the optimal weights or rules to combine the two predictions into a single, more accurate final prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYGElKNH_-Dz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Get predictions from base models on the VALIDATION set\n",
        "print(\"Training meta-model\")\n",
        "cnn_val_probs = cnn_model.predict(X_img_val)\n",
        "rf_val_probs = rf_model.predict_proba(X_num_val)[:, 1] # Get prob of class '1'\n",
        "\n",
        "# Stack these predictions into a new feature array\n",
        "# Shape will be (num_val_samples, 2)\n",
        "X_val_stacked = np.c_[cnn_val_probs, rf_val_probs]\n",
        "\n",
        "# Train the meta-model (Logistic Regression is perfect for this)\n",
        "# It learns the best \"weight\" for the CNN prob vs. the RF prob\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(X_val_stacked, y_val)\n",
        "\n",
        "print(\"Meta-model trained.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEHFR8ouAEVA"
      },
      "source": [
        "And finally, we will evaluate the final hybrid model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r1v1riZADru"
      },
      "outputs": [],
      "source": [
        "# Get predictions from base models on the TEST set\n",
        "print(\"\\n--- Final Evaluation on Test Set ---\")\n",
        "cnn_test_probs = cnn_model.predict(X_img_test)\n",
        "rf_test_probs = rf_model.predict_proba(X_num_test)[:, 1]\n",
        "\n",
        "# Stack them just like before\n",
        "X_test_stacked = np.c_[cnn_test_probs, rf_test_probs]\n",
        "\n",
        "# Get the final hybrid prediction from the meta-model\n",
        "hybrid_predictions = meta_model.predict(X_test_stacked)\n",
        "\n",
        "# Report the results\n",
        "final_accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "print(f\"\\nFinal HYBRID Model Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "print(\"\\nHybrid Model Classification Report:\")\n",
        "\n",
        "print(classification_report(y_test, hybrid_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction values for each patch in the test set\n",
        "\n",
        "hybrid_probabilities = meta_model.predict_proba(X_test_stacked)[:, 1]\n",
        "print(hybrid_probabilities)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP+ZRLytZ3wiuj5fYt0APE9",
      "include_colab_link": true,
      "mount_file_id": "1YvgAvzZJ8biMf_rGB7v2OFJOmyMK4_oO",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
